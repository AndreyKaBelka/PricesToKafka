version: "3.3"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.4
    networks:
      - docker-hadoop_default
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "22181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.0.4
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    hostname: kafka
    networks:
      - docker-hadoop_default
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8085
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka2:
    image: confluentinc/cp-kafka:7.0.4
    depends_on:
      - zookeeper
    ports:
      - "29093:29092"
    networks:
      - docker-hadoop_default
    hostname: kafka2
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka2:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8085

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8090:8080"
    restart: always
    networks:
      - docker-hadoop_default
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092,kafka2:29093
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
      - KAFKA_CLUSTERS_0_SCHEMAREGISTRY=http://schema-registry:8085
    links:
      - kafka
      - kafka2
      - zookeeper

  app:
    image: prices_to_kafka
    container_name: prices_to_kafka
    ports:
      - "8080:8080"
      - "5005:5005"
    restart: on-failure
    networks:
      - docker-hadoop_default
    depends_on:
      - kafka-ui

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    networks:
      - docker-hadoop_default
    depends_on:
      - zookeeper
      - kafka
      - kafka2
    ports:
      - '8085:8085'
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:29092,kafka2:29093"
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_SCHEMA_REGISTRY_INTER_INSTANCE_PROTOCOL: "http"
      SCHEMA_REGISTRY_LISTENERS: "http://schema-registry:8085"

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.0.4
    container_name: connect_prices_to_ozone
    ports:
      - "8083:8083"
    environment:
      - CONNECT_BOOTSTRAP_SERVERS=kafka:29092,kafka2:29092
      - CONNECT_GROUP_ID=prices
      - CONNECT_CONFIG_STORAGE_TOPIC=prices-config
      - CONNECT_OFFSET_STORAGE_TOPIC=prices-offsets
      - CONNECT_STATUS_STORAGE_TOPIC=prices-status
      - CONNECT_REST_ADVERTISED_HOST_NAME=localhost
      - CONNECT_PLUGIN_PATH=/usr/share/java,/usr/share/confluent-hub-components,/libs
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.storage.StringConverter
      - CONNECT_VALUE_CONVERTER=io.confluent.connect.avro.AvroConverter
      - CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL=http://schema-registry:8085
    volumes:
      - ./libs:/libs
    networks:
      - docker-hadoop_default

networks:
  docker-hadoop_default:
    external: true
